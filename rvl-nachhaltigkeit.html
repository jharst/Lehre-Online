<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>RVL Digitale Nachhaltigkeit</title>
    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="css/slides-extended.css" />
    <link rel="stylesheet" href="dist/theme/white.css" id="theme" />
    <link rel="stylesheet" href="plugin/highlight/zenburn.css" />
    <link rel="stylesheet" href="plugin/customcontrols/style.css">


    <link rel="stylesheet" href="./css/video-background.css" />

    <script defer src="dist/fontawesome/all.min.js"></script>
    <script defer src="plugin/load-mathjax.js"></script>

    <script type="text/javascript">
        function pageInIframe() {
            return (window.location !== window.parent.location);
        }

        let forgetPop = true;
        function onPopState(event) {
            if(forgetPop){
                forgetPop = false;
            } else if( pageInIframe()) {
                parent.postMessage(event.target.location.href, "app://obsidian.md");
            }
        }
        window.onpopstate = onPopState;
        window.onmessage = event => {
            if(event.data == "reload"){
                window.document.location.reload();
            }
            forgetPop = true;
        }

        function fitElements() {
            const itemsToFit = document.getElementsByClassName('fitText');
            for (const item in itemsToFit) {
                if (Object.hasOwnProperty.call(itemsToFit, item)) {
                    const element = itemsToFit[item];
                    fitElement(element, 1, 1000);
                    element.classList.remove('fitText');
                }
            }
        }

        function fitElement(element, start, end) {

            let size = (end + start) / 2;
            element.style.fontSize = `${size}px`;

            if (Math.abs(start - end) < 1) {
                while (element.scrollHeight > element.offsetHeight) {
                    size--;
                    element.style.fontSize = `${size}px`;
                }
                return;
            }

            if (element.scrollHeight > element.offsetHeight) {
                fitElement(element, start, size);
            } else {
                fitElement(element, size, end);
            }
        }

        document.onreadystatechange = () => {
            fitElements();
            if (document.readyState === 'complete') {
                if (pageInIframe() && window.location.href.indexOf("?export") != -1){
                    parent.postMessage(event.target.location.href, "app://obsidian.md");
                }
                if (window.location.href.indexOf("print-pdf") != -1){
                    let stateCheck = setInterval(() => {
                        clearInterval(stateCheck);
                        window.print();
                    }, 250);
                }
            }
        };
    </script>
</head>

<body>
    <div class="reveal">
        <div class="slides"><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<div class="container"><video id="background-video" autoplay muted loop style="background-image: url('./Resources/images/Anadol-Glacier-Dreams-frame.jpg');">
        <source src="./Resources/images/Anadol-clip.mp4" type="video/mp4">
</video>

<div class="left-bottom-div"><div class="left-top-div">


<div class="left-top-div-text fragment fade-out"><p class="slide-title-left">Nachhaltigkeit in digitalen Medien</p>
<p class="slide-title-left" style="align-items: flex-start; font-size: smaller;">Dr. habil. Joachim Harst<br>Allgemeine und Vergl. Literaturwissenschaft<br>Universität des Saarlandes</p>
</div>


<div class="left-top-div-text fragment fade-in-then-out"><h2>Refik Anadol: Glacier Dreams (2023)</h2>

<ul> <li>„living data paintings” und „machine hallucinations”</li> 
<li>Mustererkennung, machine learning und Bildproduktion</li>
<li>Grundlage: Datenbank von Gletscherbildern</li> 
<li>Algorithmus „erträumt” virtuelle Natur</li></ul>
</div>


<div class="left-top-div-text fragment fade-in-then-out">
<h2 style="color: white">Refik Anadol: Glacier Dreams (2023)</h2>

<blockquote>
„I realized that because these forms are going away, my ability to capture them digitally with data and AI meant I could preserve nature.” (R. Anadol)</blockquote>

<ul style="margin-top: 40px;"> 
<li>Sensibilisierung für Klimawandel?</li> 
<li>machine learning und Erderwärmung</li>
<li>virtuelle vs. tatsächliche Verflüssigung der Gletscher</li> 
</ul>
</div>


<div class="left-top-div-text fragment fade-in-then-out">
<h2>KI und Nachhaltigkeit</h2>
<ul><li>Nachhaltigkeit von KI</li>
<li>Nachhaltigkeit durch KI?</li>
<li>investigative und ästhetische Auseinandersetzungen</il>
<li>Fotografien, Diagramme, Karten</li></ul></div>



</div></div>

<div class="right-image-source"><a href="https://www.glacierdreams.com" title="Refik Anadol: Glacier Dreams, Videoinstallation. Kunsthaus Zürich, Zürich, Schweiz. Schenkung Bank Julius Bär." target="_blank">R. Anadol: Glacier Dreams (2023)<i class="fas fa-external-link-alt link-icon"></i></a></div>




<aside class="notes"><h2 id="anadol">Anadol</h2>
<ul>
<li><mark>FOLIE</mark> Was Sie hier sehen, ist ein KI-generiertes visuelles Kunstwerk von Refik Anadol. Anadol ist Computerwissenschaftler und nennt sich selbst „Datenkünstler”, seine  Werke „living data paintings”. Grund dafür ist, dass Anadols Werke häufig auf Bilddatenbanken beruhen, die er mit künstlicher Intelligenz analysieren lässt und zur Grundlage für computergenierte Animationen nimmt. Er nennt diese Werke auch „machine hallucinations” oder „machine dreams”, weil er die KI auf der Basis von vorgefundenen Mustern neue Muster generieren lässt, die sich in unserer Wirklichkeit nicht finden lassen. → Maschinelle Kreativität </li>
<li>Dieses Video ist ein Ausschnitt aus dem Werk „Glacier Dreams” von 2022, die zur Zeit im Kunsthaus Zürich zu sehen ist. Es handelt sich dabei um eine immersive Videoinstallation, einen geschlossenen Raum, der aus hochauslösenden Videodisplays besteht. Die generierte Computeranimation kann also gleichsam räumlich erfahren werden. Sie ist ein paar Minuten lang und wird im inifinite loop gezeigt; mein Ausschnitt zeigt nur einen besonders charakteristischen Abschnitt. </li>
<li>Grundlage der Animation ist eine umfangreiche Bilddatenbank von Gletschern aus aller Welt. Mehrere Millionen Bilder sind ausgewertet worden. Die Animation zeigt, wie die KI die Bilder klassifiziert und dann auf ihrer Grundlage zu „träumen” beginnt. Mein Ausschnitt zeigt eine für Anadol typische Verflüssigung der Formen. Aus den statischen Bildern werden dynamische, fluide Bewegungen erzeugt, die sich in majestätischem Fluss, in beständiger Metamorphose befinden. So wird der Eindruck eines ewigen Wandels, aber auch eines unablässigen Zusammenhangs erweckt: Alles geht in einander über, alles ist mit allem verbunden.</li>
<li><mark>FOLIE</mark> In seinen Äußerungen zum Kunstwerk erklärt Anadol, ihn habe das Bewusstsein der Vergänglichkeit der Natur zu seinem Schaffen bewogen. „I realized that because these forms are going away, my ability to capture them digitally with data and AI meant I could preserve nature.” (R. Anadol) Die Animation wird Sensibilisierung für Klimawandel beschrieben, ja als eine Form der Bewahrung einer bereits im Verschwinden befindlichen Natur.</li>
<li>Ich begegne Anadols Begeisterung für seine virtuelle Rettung der Natur mit einiger Skepsis. Schließlich ist die Entwicklung von AI ein immer größerer Faktor für die Produktion von Treibhausgasen und damit der Erderwärmung. Die riesigen Energiemengen, die zum Training von AI und zur Betreibung ihrer Infrastruktur verbraucht werden, stehen quer zu Anadols Inanspruchnahme einer Sensibilisierung. In meinen Augen ist die Verflüssigung der Formen, die man in diesem Ausschnitt sieht, eine unfreiwillige Bejahung der Verflüssigung der Gletscher, für die AI mit verantwortlich ist. In meiner Vorlesung möchte ich diesen Zusammenhängen weiter nachgehen und künstlerische Werke vorstellen, die ihn diskursiv und ästhetisch problematisieren.</li>
<li><mark>FOLIE</mark> Mein Schwerpunkt wird dabei auf dem Ressourcenverbrauch von KI und ihrer Infrastrukturen liegen. Mein einfacher Punkt ist, dass KI aktuell nicht nachhaltig entwickelt wird. Zwar gibt es verschiedene Projekte, die KI in einem zweiten Schritt für eine nachhaltige Ressourcenbewirtschaftung einsetzen wollen, aber es bleibt fraglich, ob damit die primäre Verschwendung wettgemacht werden kann. Ich muss dazu sagen, dass ich kein Fachmann für diese Zusammenhänge bin. Der Produktionshintergrund von KI ist enorm komplex und die Datenlage zum Ressourcenverbrauch unklar. Ich konzentriere mich daher auf Kunstwerke, die einerseits investigativ sind, weil sie Daten und Fakten recherchieren; und die andererseits auf ästhetischem Weg versuchen, komplexe Zusammenhänge erfahrbar zu machen.</li>
<li>Instrumente: Fotografien, Diagramme, Karten = grafische Analyse komplexer Zusammenhänge, nicht linear</div></li>
</ul>
</aside></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<div class="container" style="background-image: url(https://images.prismic.io/verticalatlas/038e5416-926b-4ca9-bc1b-5171311c548c_1920x1180_QiuZhijie_Map-of-AI.jpg?auto=compress,format&rect=0,0,1920,1180&w=1920&h=1180); background-size: cover;">


<div class="left-bottom-div fragment fade-in" style="background-color: rgba(119, 47, 139, 0.75); width: 50%"><div class="left-top-div" style="background-color: rgba(119, 47, 139); color: white; display-flex; justify-content: center; align-items: center; text-align: left; box-sizing: border-box; padding-left: 3%;">
<h2>Eine Kartografie Künstlicher Intelligenz</h2>
<ul> 
<li>topografische Karte</li>
<li>mythologische Landschaft</li> 
<li>Mindmap</li>
<li>Einschreibung von KI in materielle Welt</li></ul>
</div></div>


</div>
<div class="right-image-source is-light"><a href="https://verticalatlas.net/#qiu-zhijie-x-chen-stanley-qiufan" title="Qiu Zhijie: Map of Ai (2020). Kalligrafische Karte, fotografiert von Yan Haibo." target="_blank">Qiu Zhijie: Map of AI (2020).<i class="fas fa-external-link-alt link-icon"></i></a></div>




<aside class="notes"><h2 id="einleitende-worte-zu-zhijie">Einleitende Worte zu Zhijie</h2>
<ul>
<li><mark>FOLIE</mark> Sie sehen hier eine Karte des chinesischen Kalligrafen Qiu Zhijie mit dem Titel „Map of AI”. Sie ist Teil einer Werkserie, die komplexe Zusammenhänge in Kartenform aufbereitet. Die Karten können dabei verschiedene Größen haben. Sie werden u.a. als Wandgemälde und großformatige Projektionen auf Gebäuden inszeniert. → Frage an Publikum</li>
</ul>
<h2 id="brainstorming-zu-seinen-karten">Brainstorming zu seinen Karten</h2>
<ul>
<li>Klassifizierung verschiedenster Bereiche im Zusammenhang mit AI (Programmiersprachen, Hardware, Machine Learning Strategien, Firmen, etc.) – Zusammenhänge werden allerdings von der Grafik nicht näher erläutert</li>
<li>Einschreibung von KI in die materielle Welt – Technik beruht auf Ausbeutung von materiellen Ressourcen, Umstrukturierung von Produktionsprozessen, globalen Lieferketten, prekären Arbeitsverhältnissen – eine weltumspannende Infrastruktur, von der unsere Endgeräte nur die Spitze des Eisbergs sind – und wie beim Eisberg ist der größte Teil dieser Infrastruktur unsichtbar</li>
<li><mark>FOLIE</mark> Aspekte<ul>
<li>topografische Karte</li>
<li>mythologische Landschaft</li>
<li>Mindmap</li>
<li>Einschreibung von KI in die materielle Welt</div></li>
</ul>
</li>
</ul>
</aside></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<style> 

#animatedBackground { 
    position: relative;
    background-size: cover; 
    animation: backgroundChange 10s infinite; 
}

@keyframes backgroundChange { 
    0%, 32% {
        background-image: url('https://images.prismic.io/verticalatlas/df60a55b-01c9-47c2-91f8-d7e15dd6b568_2015_Farm-CouncilBluffs_Gerrard_017.png?auto=compress,format&rect=0,0,3840,2160&w=1920&h=1080');
        opacity: 1;
    }
    33%, 66% {
        background-image: url('https://images.prismic.io/verticalatlas/d6551f3a-d924-4665-9a6b-14bdcc44e0d2_2015_Farm-CouncilBluffs_Gerrard_010.png?auto=compress,format&rect=0,0,3840,2160&w=1920&h=1080');
        opacity: 1;
    }
    67%, 100% {
        background-image: url('https://images.prismic.io/verticalatlas/c5572dcd-fbe1-4ebc-a227-1f8f0f891ac1_2015_Farm-CouncilBluffs_Gerrard_013.png?auto=compress,format&rect=0,0,3840,2160&w=1920&h=1080');
        opacity: 1;
    }
}
</style>

<div class="container" id="animatedBackground">


<div class="left-bottom-div fragment fade-in-then-out"><div class="left-top-div"><div class="left-top-div-text"><blockquote><i class="fa fa-quote-left  fa-2x fa-pull-left" aria-hidden="true"></i>The viewer is slowly led through the environment. A slow-motion hyperrealistic impression provides glimpses of a usually invisible place. The slowness of the images indirectly emphasizes the unimaginable amount of data that is processed here hour after hour, day after day. This is a visual representation of the robust house where the Internet lives. The heavy matter and energy that the cloud actually consists of are made tangible.<p style="font-size: smaller; margin-top: 20px !important;">Quelle: <a href="https://verticalatlas.net/#john-gerrard" title="Dellanoce, L., et al. (Hrsg.). (2022). Vertical Atlas. ArtEZ Press. https://verticalatlas.net/">Vertical Atlas</a></p></blockquote></div></div></div>



<div class="left-bottom-div fragment fade-in-then-out"><div class="left-top-div"><div class="left-top-div-text">
<h2>Die Materialität<br>der Cloud</h2>
<ul><li>„hyperscale data centers”</li> 
<li>Größe: bis zu 4km<sup>2</sup></li>
<li>Anschlussleistungs: 1000 MW</li>
<li>Wasserverbrauch 2023 global: 30 Mrd. Liter</li>
<li>exponentielle Steigerung erwartet</li></ul>
<p style="font-size: smaller; margin-top: 20px !important;">Quelle: <a href="https://www.greenpeace.de/ueber-uns/loesungen-finden/kuenstliche-intelligenz-energieverbrauch-und-umweltauswirkungen" title="Greenpeace: Künstliche Intelligenz: Energieverbrauch und Umweltauswirkungen. (2025, May 14).">Greenpeace-Report</a></p>
</div></div></div>


<div class="fragment fade-in-then-out" style="width: 65%; height: auto;"><img src="/Resources/images/Global-DC-Electricity-Consumption.jpg" style="border: solid #772F8B 5px; border-radius: 4px;"></div>


<div class="left-bottom-div fragment fade-in-then-out"><div class="left-top-div"><div class="left-top-div-text"><blockquote><i class="fa fa-quote-left  fa-2x fa-pull-left" aria-hidden="true"></i>the carbon footprint of training a single big language model is equal to around 300,000 kg of carbon dioxide emissions. This is of the order of 125 round-trip flights between New York and Beijing (Strubell et al. 2019).</blockquote>

<blockquote><i class="fa fa-quote-left  fa-2x fa-pull-left" aria-hidden="true"></i>For a linear gain in performance, an exponentially larger model is required, which can come in the form of increasing the amount of training data or the number of experiments, thus escalating computational costs, and therefore carbon emissions (Dhar 2020).</blockquote></div></div></div>


<div class="right-image-source is-dark"><a href="https://verticalatlas.net/#john-gerrard" title="John Gerrard: _FARM (COUNCIL BLUFFS, IOWA) 2015,_ 2015." target="_blank">J. Gerrard: Farm (2015)<i class="fas fa-external-link-alt link-icon"></i></a></div>


<aside class="notes"><h2 id="einleitende-worte-zu-gerrard">Einleitende Worte zu Gerrard</h2>
<ul>
<li>…eine weltumspannende Infrastruktur, von der unsere Endgeräte nur die Spitze des Eisbergs sind – und wie beim Eisberg ist der größte Teil dieser Infrastruktur für die gewöhnlichen Nutzer unsichtbar</li>
<li>Ich zeige Ihnen hier drei Fotografien aus einer digitalen Visualisation des irischen Künstlers John Gerrard. Gerrard beschäftigt sich in vielen seiner Werke damit, die materielle Infrastruktur des Internets sichtbar zu machen. In Werken mit dem Titel „Farm” porträtiert er Rechenzentren von Google. Weil Google ihm den Zutritt zu den Rechenzentren untersagt hat, hat Gerrard das Gelände mit einem Hubschrauber überflogen. Die dabei entstandenen Aufnahmen aus der Vogelperspektive hat er zur Datengrundlage einer virtuellen Rekonstruktion genommen, die das Rechenzentrum jetzt als begehbares 3D-Modell darstellen. Das ausgestellte Ergebnis ist eine digitale Animation, die in entnervender Langsamkeit durch das Rechenzentrum führt.</li>
<li><mark>FOLIE</mark> Gerrard schreib dazu: „The viewer is slowly led through the environment. A slow-motion hyperrealistic impression provides glimpses of a usually invisible place. The slowness of the images indirectly emphasizes the unimaginable amount of data that is processed here hour after hour, day after day. This is a visual representation of the robust house where the Internet lives. The heavy matter and energy that the cloud actually consists of are made tangible.”</li>
</ul>
<h2 id="die-materialität-der-cloud">Die Materialität der Cloud</h2>
<ul>
<li><mark>FOLIE</mark> Um KI zu entwickeln und zu betreiben, werden sog. „hyperscale data centers” gebaut, die herkömmliche Rechenzentren in ihren Dimensionen weit übertreffen. Die Datenlage ist unklar, weil es keine einheitlichen Gesetze gibt, die Firmen zur Offenlegung ihres Ressourcenverbrauchs verpflichten. Die folgenden Angaben stammen aus einer Greenpeace-Studie, die eine große Zahl weiterer Studien ausgewertet hat. Auf ihrer Basis lassen sich die folgenden Angaben machen, um die Dimensionen von hyperscale data centers einzuschätzen:<ul>
<li>Ein einziges Hyperscale-Rechenzentrum mit einer Anschlussleistung von 1.000 Megawatt verbraucht so viel Strom wie eine europäische Stadt mit 1 Million Einwohnern. Die Fläche eines solchen Zentrums kann bis zu 4 Quadratkilometern betragen und damit die Größe eines Stadtteils haben (S. 19)</li>
<li>Zur Kühlung der Server werden riesige Wassermengen benötigt. 2023 lag der gesamte Wasserverbrauch aller AI-Rechenzentren weltweit bereits bei 30 Milliarden Litern (S. 24). In trockenen Regionen treten „hyperscale data centers” in direkte Konkurrenz mit der Bevölkerung und graben ihr im Wortsinne das Wasser ab.</li>
<li>Es wird damit gerechnet, dass der Ressourcenverbrauch der Rechenzentren exponentiell steigen wird. Greenpeace geht in einem moderaten Szenario von einer Steigerung des anteiligen Stromverbrauchs um 16% pro Jahr aus, was eine Verdreifachung bis 2030 bedeuten würde. (s. Diagramm)</li>
</ul>
</li>
</ul>
<h2 id="gründe-für-den-energieverbrauch">Gründe für den Energieverbrauch</h2>
<p><mark>FOLIE</mark></p>
<ul>
<li>[&quot;] the carbon footprint of training a single big language model is equal to around 300,000 kg of carbon dioxide emissions. This is of the order of 125 round-trip flights between New York and Beijing [@Dhar-2020; @Strubell-2019]</li>
<li>[&quot;] For a linear gain in performance, an exponentially larger model is required, which can come in the form of increasing the amount of training data or the number of experiments, thus escalating computational costs, and therefore carbon emissions [@Dhar-2020, 425]. </li>
<li>Datenverarbeitung als Basis für machine learning – „scraping” des Internets (Datenabruf, -aufbereitung und -speicherung) – Training (weitere Datenverarbeitung) – AI-Chips mit besonders hohem Stromverbrauch (GPU und TPU)</li>
<li>Bedeutung von Cloud Computing und offenem Zugang zu KI – Möglichkeit für jeden, eigene Modelle zu trainieren – Integration von AI im Hintergrund beliebiger Anwendungen</li>
<li>stetiges Steigen der Parameter von LLMs – entsprechende Steigerung des Energieverbrauchs bei Datenverarbeitung und training</div></li>
</ul>
</aside></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<div class="container bg-video-wrapper">
<iframe src="https://anatomyof.ai/index.html" frameborder="0"></iframe>
<div class="left-bottom-div fragment" style="z-index: 2;"><div class="left-top-div"><div class="left-top-div-text"><blockquote style="font-size: smaller">With each interaction, Alexa is training to hear better, to interpret more precisely, to trigger actions that map to the user’s commands more accurately, and to build a more complete model of their preferences, habits and desires. What is required to make this possible? <strong>Put simply: each small moment of convenience – be it answering a question, turning on a light, or playing a song – requires a vast planetary network, fueled by the extraction of non-renewable materials, labor, and data.</strong> The scale of resources required is many magnitudes greater than the energy and labor it would take a human to operate a household appliance or flick a switch. A full accounting for these costs is almost impossible, but it is increasingly important that we grasp the scale and scope if we are to understand and govern the technical infrastructures that thread through our lives.</blockquote></div></div>
</div>
</div></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" template="" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<div class="iframe-container">
<iframe src="https://anatomyof.ai/index.html" title="" width="1920" height="1080" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

<aside class="notes"><h2 id="breast-milk-of-the-volcano">Breast-Milk of the Volcano</h2>
</div></aside></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" template="" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<aside class="notes"><h2 id="solar-poems">Solar Poems</h2>
</div></aside></script></section><section  data-markdown><script type="text/template"><!-- .slide: class="has-light-background drop" data-background-color="lightgrey" -->
<div class="" style="position: absolute; left: 0px; top: 0px; height: 1080px; width: 1920px; min-height: 1080px; display: flex; flex-direction: column; align-items: start; justify-content: center" absolute="true">

<style>
/* Wrapper füllt die ganze container-Fläche */
.bg-video-wrapper { 
	position: absolute; 
	inset: 0; 
	overflow: hidden; 
	z-index: 0; 
	pointer-events: none; 
}

/* iframe zentrieren und cover-Verhalten erzwingen */
.bg-video-wrapper iframe {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%,-50%);
  min-width: 100%;
  min-height: 100%;
  width: auto;
  height: auto;
}
</style>

<div class="container" style="overflow: hidden;">
<div class="bg-video-wrapper">
<iframe id="background-iframe" src="https://player.vimeo.com/video/53900017?autoplay=1&muted=1&loop=1&background=1&controls=0&autopause=0" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
</div></div>
</div></script></section></div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/obsidian-markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>

    <script src="plugin/zoom/zoom.js"></script>
    <script src="plugin/math/math.js"></script>
    <script src="plugin/mermaid/mermaid.js"></script>
    <script src="plugin/chart/chart.umd.js"></script>
    <script src="plugin/chart/plugin.js"></script>
    <script src="plugin/menu/menu.js"></script>
    <script src="plugin/customcontrols/plugin.js"></script>

    <script>
        function extend() {
            const target = {};
            for (let i = 0; i < arguments.length; i++) {
                const source = arguments[i];
                for (const key in source) {
                    if (source.hasOwnProperty(key)) {
                        target[key] = source[key];
                    }
                }
            }
            return target;
        }

        function isLight(color) {
            let hex = color.replace('#', '');

            // convert #fff => #ffffff
            if (hex.length == 3) {
                hex = `${hex[0]}${hex[0]}${hex[1]}${hex[1]}${hex[2]}${hex[2]}`;
            }

            const c_r = parseInt(hex.substr(0, 2), 16);
            const c_g = parseInt(hex.substr(2, 2), 16);
            const c_b = parseInt(hex.substr(4, 2), 16);
            const brightness = ((c_r * 299) + (c_g * 587) + (c_b * 114)) / 1000;
            return brightness > 155;
        }

        const bgColor = getComputedStyle(document.documentElement).getPropertyValue('--r-background-color').trim();

        if (isLight(bgColor)) {
            document.body.classList.add('has-light-background');
        } else {
            document.body.classList.add('has-dark-background');
        }

        // default options to init reveal.js
        const defaultOptions = {
            controls: true,
            progress: true,
            history: true,
            center: true,
            transition: 'default', // none/fade/slide/convex/concave/zoom
            plugins: [
                ObsidianMarkdown,
                RevealHighlight,
                RevealZoom,
                RevealNotes,
                RevealMath.MathJax3,
                RevealMermaid,
                RevealChart,
                RevealCustomControls,
                RevealMenu,
            ],
            allottedTime: 120 * 1000,
            mathjax3: {
                mathjax: 'plugin/math/mathjax/tex-chtml.js',
            },
            markdown: {
                gfm: true,
            },
            mermaid: {
                theme: isLight(bgColor) ? 'default' : 'dark',
            },
            customcontrols: {
                controls: [
                ]
            },
            menu: {
                loadIcons: false
            }
        };

        if ( pageInIframe() ) {
            defaultOptions.scrollActivationWidth = 5;
        }

        // options from URL query string
        const queryOptions = Reveal().getQueryHash() || {};

        const options = extend(defaultOptions, {"controls":true,"progress":true,"slideNumber":true,"center":false,"transition":"slide","transitionSpeed":"default","width":1920,"height":1080,"margin":0.04}, queryOptions);
    </script>

    <script>
      Reveal.initialize(options);
    </script>
    <!-- created with Slides Extended reveal.html template -->
</body>
</html>
